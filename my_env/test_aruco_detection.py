#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
test_aruco_detection.py  â€”â€”  æµ‹è¯•ArUcoæ£€æµ‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
ç”¨æ³•ï¼špython test_aruco_detection.py
"""

import numpy as np
import cv2
import pyrealsense2 as rs
import time
from typing import Optional

# ArUco å‚æ•°
ARUCO_DICT = cv2.aruco.DICT_ARUCO_ORIGINAL
ARUCO_SIZE = 0.05  # ArUcoæ ‡è®°å®é™…å°ºå¯¸ï¼ˆç±³ï¼‰

def test_camera_and_aruco():
    """æµ‹è¯•ç›¸æœºè¿æ¥å’ŒArUcoæ£€æµ‹"""
    
    # åˆå§‹åŒ–ArUcoæ£€æµ‹å™¨
    aruco_dict = cv2.aruco.getPredefinedDictionary(ARUCO_DICT)
    aruco_params = cv2.aruco.DetectorParameters()
    detector = cv2.aruco.ArucoDetector(aruco_dict, aruco_params)
    
    # æŸ¥æ‰¾ç›¸æœº
    ctx = rs.context()
    devices = ctx.query_devices()
    
    if len(devices) == 0:
        print("âŒ æœªæ‰¾åˆ°RealSenseç›¸æœº")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(devices)} å°RealSenseç›¸æœº:")
    for i, dev in enumerate(devices):
        serial = dev.get_info(rs.camera_info.serial_number)
        name = dev.get_info(rs.camera_info.name)
        print(f"  {i+1}. {name} (åºåˆ—å·: {serial})")
    
    # ä½¿ç”¨ç¬¬ä¸€å°ç›¸æœºè¿›è¡Œæµ‹è¯•
    first_device = devices[2]
    serial = first_device.get_info(rs.camera_info.serial_number)
    
    print(f"\nğŸ”§ æµ‹è¯•ç›¸æœº: {serial}")
    
    # é…ç½®ç›¸æœº
    pipeline = rs.pipeline()
    config = rs.config()
    config.enable_device(serial)
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
    
    try:
        # å¯åŠ¨ç›¸æœº
        profile = pipeline.start(config)
        
        # è·å–ç›¸æœºå†…å‚
        color_stream = profile.get_stream(rs.stream.color)
        intrinsics = color_stream.as_video_stream_profile().get_intrinsics()
        
        camera_matrix = np.array([
            [intrinsics.fx, 0, intrinsics.ppx],
            [0, intrinsics.fy, intrinsics.ppy],
            [0, 0, 1]
        ], dtype=np.float32)
        
        dist_coeffs = np.array(intrinsics.coeffs, dtype=np.float32)
        
        print(f"  ğŸ“· åˆ†è¾¨ç‡: {intrinsics.width}x{intrinsics.height}")
        print(f"  ğŸ” ç„¦è·: fx={intrinsics.fx:.1f}, fy={intrinsics.fy:.1f}")
        
        print("\nğŸ¯ å¼€å§‹ArUcoæ£€æµ‹æµ‹è¯•...")
        print("è¯·å°†ArUcoæ ‡è®°æ”¾åœ¨ç›¸æœºå‰ï¼ŒæŒ‰ 'q' é€€å‡º, æŒ‰ 's' ä¿å­˜å›¾åƒ")
        
        frame_count = 0
        detection_count = 0
        
        while True:
            try:
                # è·å–å›¾åƒ
                frames = pipeline.wait_for_frames(timeout_ms=1000)
                color_frame = frames.get_color_frame()
                
                if not color_frame:
                    continue
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                image = np.asanyarray(color_frame.get_data())
                frame_count += 1
                
                # æ£€æµ‹ArUco
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                corners, ids, _ = detector.detectMarkers(gray)
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                display_image = image.copy()
                
                if ids is not None and len(ids) > 0:
                    detection_count += 1
                    
                    # ç»˜åˆ¶æ ‡è®°
                    cv2.aruco.drawDetectedMarkers(display_image, corners, ids)
                    
                    # å°è¯•ä¼°è®¡å§¿æ€
                    try:
                        # å°è¯•ä¸åŒçš„API
                        success = False
                        try:
                            rvecs, tvecs, _ = cv2.aruco.estimatePoseSingleMarkers(
                                corners, ARUCO_SIZE, camera_matrix, dist_coeffs
                            )
                            success = True
                        except AttributeError:
                            try:
                                rvecs, tvecs, _ = cv2.estimatePoseSingleMarkers(
                                    corners, ARUCO_SIZE, camera_matrix, dist_coeffs
                                )
                                success = True
                            except AttributeError:
                                # æ‰‹åŠ¨è®¡ç®—
                                half_size = ARUCO_SIZE / 2.0
                                object_points = np.array([
                                    [-half_size, -half_size, 0],
                                    [half_size, -half_size, 0],
                                    [half_size, half_size, 0],
                                    [-half_size, half_size, 0]
                                ], dtype=np.float32)
                                
                                success_pnp, rvec, tvec = cv2.solvePnP(
                                    object_points, 
                                    corners[0].reshape(-1, 2), 
                                    camera_matrix, 
                                    dist_coeffs
                                )
                                
                                if success_pnp:
                                    rvecs = [rvec.flatten()]
                                    tvecs = [tvec.flatten()]
                                    success = True
                        
                        if success:
                            # ç»˜åˆ¶åæ ‡è½´
                            for i in range(len(rvecs)):
                                cv2.drawFrameAxes(display_image, camera_matrix, dist_coeffs, 
                                                rvecs[i], tvecs[i], 0.03)
                            
                            # æ˜¾ç¤ºä½ç½®ä¿¡æ¯
                            pos_text = f"Pos: ({tvecs[0][0]:.3f}, {tvecs[0][1]:.3f}, {tvecs[0][2]:.3f})"
                            cv2.putText(display_image, pos_text, (10, 30), 
                                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                    
                    except Exception as e:
                        print(f"å§¿æ€ä¼°è®¡å¤±è´¥: {e}")
                    
                    # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„æ ‡è®°ID
                    id_text = f"ID: {ids.flatten()}"
                    cv2.putText(display_image, id_text, (10, 60), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                stats_text = f"Frame: {frame_count}, Detected: {detection_count}"
                cv2.putText(display_image, stats_text, (10, display_image.shape[0] - 10), 
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # æ˜¾ç¤ºå›¾åƒ
                cv2.imshow(f"ArUco Test - Camera {serial[:8]}", display_image)
                
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord('s'):
                    filename = f"aruco_test_{serial}_{int(time.time())}.jpg"
                    cv2.imwrite(filename, display_image)
                    print(f"ä¿å­˜å›¾åƒ: {filename}")
                
            except Exception as e:
                print(f"å¤„ç†å¸§æ—¶å‡ºé”™: {e}")
                time.sleep(0.1)
        
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœ:")
        print(f"  æ€»å¸§æ•°: {frame_count}")
        print(f"  æ£€æµ‹æˆåŠŸ: {detection_count}")
        if frame_count > 0:
            success_rate = (detection_count / frame_count) * 100
            print(f"  æˆåŠŸç‡: {success_rate:.1f}%")
        
    except Exception as e:
        print(f"âŒ ç›¸æœºæµ‹è¯•å¤±è´¥: {e}")
    
    finally:
        try:
            pipeline.stop()
            cv2.destroyAllWindows()
        except:
            pass
        print("ğŸ”§ ç›¸æœºèµ„æºå·²é‡Šæ”¾")

if __name__ == "__main__":
    print("ArUcoæ£€æµ‹æµ‹è¯•å·¥å…·")
    print("=" * 30)
    test_camera_and_aruco() 